<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>12fddad684c04fe0bce62b7368fa9a4b</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell markdown" id="NQnPJ26nvkTM">
<h1 id="nour-amr-sayed-abdou-kotb">Nour Amr Sayed Abdou Kotb</h1>
<h1 id="gh1028950">GH1028950</h1>
<h1 id="m508a-big-data-analytics">M508A Big Data Analytics</h1>
<h1 id="dataset-about-british-airline-reviews-kaggle">Dataset about:
British airline reviews (Kaggle)</h1>
</div>
<section id="introduction" class="cell markdown" id="dlkbZOSc6Uqe">
<h1>Introduction</h1>
</section>
<div class="cell markdown" id="QJmebiX06r8R">
<p>This project focuses on building an end to end NLP pipeling to
analyse the customer's reviews in British airline. Through this NLP
pipeline I will use mulitple machine learning models either traditional
way or deep learning one, to determine the most accurate and effective
one.</p>
</div>
<section id="problem-statement" class="cell markdown" id="aLItuXS46tTA">
<h1>Problem Statement</h1>
</section>
<div class="cell markdown" id="MKXBmrOj6vxL">
<p>In the airline Industry, the customer satisfaction plays an important
role in business, and the airline reputation. One of the key indicators
about any airline specially here the British airline is whether the
customers would recommend our airline or not. So based on customers
feedback, our airline will have a good income, reputation, etc. but also
the customer feedback is so important to know which points we have lack
at and so we could imporve our services.</p>
<p>As a data scientest at British airline I will analyze customer
reviews so we can predict their recommendations. By automating this
prediction, the airline can do some improvments and recommendation
leading to a better customer satisfiction.</p>
</div>
<section id="reference-for-the-dataset" class="cell markdown"
id="nJEAOI5O6yMy">
<h1>Reference for the dataset</h1>
</section>
<div class="cell markdown" id="fOzE4EWN6KX2">
<p><a
href="https://www.kaggle.com/datasets/dharun4772/british-airline-review-dataset"
class="uri">https://www.kaggle.com/datasets/dharun4772/british-airline-review-dataset</a></p>
</div>
<section id="import-libraries" class="cell markdown" id="247N8VtMLCxu">
<h1>Import Libraries</h1>
</section>
<div class="cell code" data-execution_count="17"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="tYBW0RXAh2BQ" data-outputId="00dec52f-ddd3-4687-d125-a04ff6668d5b">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install textacy</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> textacy</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> spacy.load(<span class="st">&quot;en_core_web_sm&quot;</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">&quot;max_colwidth&quot;</span>, <span class="va">None</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn.metrics.pairwise</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem <span class="im">import</span> WordNetLemmatizer</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn.ensemble</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>label_encoder <span class="op">=</span> LabelEncoder()</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span>  accuracy_score, precision_score, recall_score, f1_score, confusion_matrix</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> transformers</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install datasets</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> datasets</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: textacy in /usr/local/lib/python3.10/dist-packages (0.13.0)
Requirement already satisfied: cachetools&gt;=4.0.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (5.5.0)
Requirement already satisfied: catalogue~=2.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (2.0.10)
Requirement already satisfied: cytoolz&gt;=0.10.1 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.0.1)
Requirement already satisfied: floret~=0.10.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (0.10.5)
Requirement already satisfied: jellyfish&gt;=0.8.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.1.2)
Requirement already satisfied: joblib&gt;=0.13.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.4.2)
Requirement already satisfied: networkx&gt;=2.7 in /usr/local/lib/python3.10/dist-packages (from textacy) (3.4.2)
Requirement already satisfied: numpy&gt;=1.17.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.26.4)
Requirement already satisfied: pyphen&gt;=0.10.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (0.17.0)
Requirement already satisfied: requests&gt;=2.10.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (2.32.3)
Requirement already satisfied: scipy&gt;=1.8.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.13.1)
Requirement already satisfied: scikit-learn&gt;=1.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.5.2)
Requirement already satisfied: spacy~=3.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (3.7.5)
Requirement already satisfied: tqdm&gt;=4.19.6 in /usr/local/lib/python3.10/dist-packages (from textacy) (4.66.6)
Requirement already satisfied: toolz&gt;=0.8.0 in /usr/local/lib/python3.10/dist-packages (from cytoolz&gt;=0.10.1-&gt;textacy) (0.12.1)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.10.0-&gt;textacy) (3.4.0)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.10.0-&gt;textacy) (3.10)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.10.0-&gt;textacy) (2.2.3)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.10.0-&gt;textacy) (2024.8.30)
Requirement already satisfied: threadpoolctl&gt;=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn&gt;=1.0-&gt;textacy) (3.5.0)
Requirement already satisfied: spacy-legacy&lt;3.1.0,&gt;=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0-&gt;textacy) (3.0.12)
Requirement already satisfied: spacy-loggers&lt;2.0.0,&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0-&gt;textacy) (1.0.5)
Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0-&gt;textacy) (1.0.11)
Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0-&gt;textacy) (2.0.10)
Requirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0-&gt;textacy) (3.0.9)
Requirement already satisfied: thinc&lt;8.3.0,&gt;=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0-&gt;textacy) (8.2.5)
Requirement already satisfied: wasabi&lt;1.2.0,&gt;=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0-&gt;textacy) (1.1.3)
Requirement already satisfied: srsly&lt;3.0.0,&gt;=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0-&gt;textacy) (2.4.8)
Requirement already satisfied: weasel&lt;0.5.0,&gt;=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0-&gt;textacy) (0.4.1)
Requirement already satisfied: typer&lt;1.0.0,&gt;=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0-&gt;textacy) (0.15.1)
Requirement already satisfied: pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0-&gt;textacy) (2.10.3)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0-&gt;textacy) (3.1.4)
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0-&gt;textacy) (75.1.0)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0-&gt;textacy) (24.2)
Requirement already satisfied: langcodes&lt;4.0.0,&gt;=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0-&gt;textacy) (3.5.0)
Requirement already satisfied: language-data&gt;=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes&lt;4.0.0,&gt;=3.2.0-&gt;spacy~=3.0-&gt;textacy) (1.3.0)
Requirement already satisfied: annotated-types&gt;=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy~=3.0-&gt;textacy) (0.7.0)
Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy~=3.0-&gt;textacy) (2.27.1)
Requirement already satisfied: typing-extensions&gt;=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy~=3.0-&gt;textacy) (4.12.2)
Requirement already satisfied: blis&lt;0.8.0,&gt;=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc&lt;8.3.0,&gt;=8.2.2-&gt;spacy~=3.0-&gt;textacy) (0.7.11)
Requirement already satisfied: confection&lt;1.0.0,&gt;=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc&lt;8.3.0,&gt;=8.2.2-&gt;spacy~=3.0-&gt;textacy) (0.1.5)
Requirement already satisfied: click&gt;=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy~=3.0-&gt;textacy) (8.1.7)
Requirement already satisfied: shellingham&gt;=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy~=3.0-&gt;textacy) (1.5.4)
Requirement already satisfied: rich&gt;=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy~=3.0-&gt;textacy) (13.9.4)
Requirement already satisfied: cloudpathlib&lt;1.0.0,&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy~=3.0-&gt;textacy) (0.20.0)
Requirement already satisfied: smart-open&lt;8.0.0,&gt;=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy~=3.0-&gt;textacy) (7.0.5)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;spacy~=3.0-&gt;textacy) (3.0.2)
Requirement already satisfied: marisa-trie&gt;=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data&gt;=1.2-&gt;langcodes&lt;4.0.0,&gt;=3.2.0-&gt;spacy~=3.0-&gt;textacy) (1.2.1)
Requirement already satisfied: markdown-it-py&gt;=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy~=3.0-&gt;textacy) (3.0.0)
Requirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy~=3.0-&gt;textacy) (2.18.0)
Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open&lt;8.0.0,&gt;=5.2.1-&gt;weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy~=3.0-&gt;textacy) (1.17.0)
Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py&gt;=2.2.0-&gt;rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy~=3.0-&gt;textacy) (0.1.2)
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu
  warnings.warn(Warnings.W111)
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)
Requirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)
Requirement already satisfied: pyarrow&gt;=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)
Requirement already satisfied: dill&lt;0.3.9,&gt;=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)
Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)
Requirement already satisfied: requests&gt;=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)
Requirement already satisfied: tqdm&gt;=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)
Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)
Requirement already satisfied: multiprocess&lt;0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)
Requirement already satisfied: fsspec&lt;=2024.9.0,&gt;=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]&lt;=2024.9.0,&gt;=2023.1.0-&gt;datasets) (2024.9.0)
Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)
Requirement already satisfied: huggingface-hub&gt;=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.5)
Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)
Requirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)
Requirement already satisfied: aiohappyeyeballs&gt;=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets) (2.4.4)
Requirement already satisfied: aiosignal&gt;=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets) (1.3.1)
Requirement already satisfied: async-timeout&lt;6.0,&gt;=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets) (4.0.3)
Requirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets) (24.2.0)
Requirement already satisfied: frozenlist&gt;=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets) (1.5.0)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets) (6.1.0)
Requirement already satisfied: propcache&gt;=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets) (0.2.1)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets) (1.18.3)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&gt;=0.23.0-&gt;datasets) (4.12.2)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.32.2-&gt;datasets) (3.4.0)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.32.2-&gt;datasets) (3.10)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.32.2-&gt;datasets) (2.2.3)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.32.2-&gt;datasets) (2024.8.30)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas-&gt;datasets) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-&gt;datasets) (2024.2)
Requirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas-&gt;datasets) (2024.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;datasets) (1.17.0)
</code></pre>
</div>
</div>
<div class="cell markdown" id="PwA-dRmIk3jZ">
<p>Imported the needed libraries in my code</p>
</div>
<section id="load-the-dataset" class="cell markdown" id="ha7VyhhpLQnG">
<h1>Load the dataset</h1>
</section>
<div class="cell code" data-execution_count="18" id="apGI7pHDiOos">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&quot;/content/airline_review.csv&quot;</span>)</span></code></pre></div>
</div>
<div class="cell markdown" id="dZWNmO-Xk90p">
<p>Loaded the dataset that I will work on it.</p>
</div>
<section id="exploratory-data-anaylsis-eda" class="cell markdown"
id="X91wOf6cLssU">
<h1>Exploratory Data Anaylsis (EDA)</h1>
</section>
<div class="cell code" data-execution_count="19"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="heKuGo1dDhqH" data-outputId="70dd549e-c787-4408-9feb-8eb1768a3b3a">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>df.info()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 3616 entries, 0 to 3615
Data columns (total 20 columns):
 #   Column               Non-Null Count  Dtype 
---  ------               --------------  ----- 
 0   Unnamed: 0           3616 non-null   int64 
 1   rating               3616 non-null   int64 
 2   header               3616 non-null   object
 3   author               3616 non-null   object
 4   date                 3616 non-null   object
 5   place                3616 non-null   object
 6   content              3616 non-null   object
 7   aircraft             1902 non-null   object
 8   traveller_type       2895 non-null   object
 9   seat_type            3614 non-null   object
 10  route                2891 non-null   object
 11  date_flown           2888 non-null   object
 12  seat_comfort         3616 non-null   int64 
 13  cabin_staff_service  3616 non-null   int64 
 14  food_beverages       3616 non-null   int64 
 15  ground_service       3616 non-null   int64 
 16  value_for_money      3616 non-null   int64 
 17  recommended          3616 non-null   object
 18  entertainment        3616 non-null   int64 
 19  trip_verified        2142 non-null   object
dtypes: int64(8), object(12)
memory usage: 565.1+ KB
</code></pre>
</div>
</div>
<div class="cell markdown" id="3EPCKLK8IV9J">
<p>To know the number of enteries (rows and columns)</p>
</div>
<div class="cell code" data-execution_count="20"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="jOmVq6QZjBEk" data-outputId="df9fd7b1-efdb-455c-cd31-61bd44400fb1">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>df.columns</span></code></pre></div>
<div class="output execute_result" data-execution_count="20">
<pre><code>Index([&#39;Unnamed: 0&#39;, &#39;rating&#39;, &#39;header&#39;, &#39;author&#39;, &#39;date&#39;, &#39;place&#39;, &#39;content&#39;,
       &#39;aircraft&#39;, &#39;traveller_type&#39;, &#39;seat_type&#39;, &#39;route&#39;, &#39;date_flown&#39;,
       &#39;seat_comfort&#39;, &#39;cabin_staff_service&#39;, &#39;food_beverages&#39;,
       &#39;ground_service&#39;, &#39;value_for_money&#39;, &#39;recommended&#39;, &#39;entertainment&#39;,
       &#39;trip_verified&#39;],
      dtype=&#39;object&#39;)</code></pre>
</div>
</div>
<div class="cell markdown" id="hkN_CcrFiq2o">
<p>To check the list of columns in the dataset</p>
</div>
<div class="cell code" data-execution_count="21" id="qPqCCkGwDlFz">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop_duplicates()</span></code></pre></div>
</div>
<div class="cell markdown" id="Zmfhkfa1Ieup">
<p>To remove all duplicates in the dataset</p>
</div>
<div class="cell code" data-execution_count="22"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
id="VayjfdXzDp7N" data-outputId="a04777c3-ff63-497a-9012-f64ac56a066a">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>df.isnull().<span class="bu">sum</span>()</span></code></pre></div>
<div class="output execute_result" data-execution_count="22">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Unnamed: 0</th>
      <td>0</td>
    </tr>
    <tr>
      <th>rating</th>
      <td>0</td>
    </tr>
    <tr>
      <th>header</th>
      <td>0</td>
    </tr>
    <tr>
      <th>author</th>
      <td>0</td>
    </tr>
    <tr>
      <th>date</th>
      <td>0</td>
    </tr>
    <tr>
      <th>place</th>
      <td>0</td>
    </tr>
    <tr>
      <th>content</th>
      <td>0</td>
    </tr>
    <tr>
      <th>aircraft</th>
      <td>1714</td>
    </tr>
    <tr>
      <th>traveller_type</th>
      <td>721</td>
    </tr>
    <tr>
      <th>seat_type</th>
      <td>2</td>
    </tr>
    <tr>
      <th>route</th>
      <td>725</td>
    </tr>
    <tr>
      <th>date_flown</th>
      <td>728</td>
    </tr>
    <tr>
      <th>seat_comfort</th>
      <td>0</td>
    </tr>
    <tr>
      <th>cabin_staff_service</th>
      <td>0</td>
    </tr>
    <tr>
      <th>food_beverages</th>
      <td>0</td>
    </tr>
    <tr>
      <th>ground_service</th>
      <td>0</td>
    </tr>
    <tr>
      <th>value_for_money</th>
      <td>0</td>
    </tr>
    <tr>
      <th>recommended</th>
      <td>0</td>
    </tr>
    <tr>
      <th>entertainment</th>
      <td>0</td>
    </tr>
    <tr>
      <th>trip_verified</th>
      <td>1474</td>
    </tr>
  </tbody>
</table>
</div><br><label><b>dtype:</b> int64</label>
</div>
</div>
<div class="cell markdown" id="TqdPz7RUIlKI">
<p>To check for any missing values</p>
</div>
<div class="cell code" data-execution_count="23" id="l6Ch_LemDuaw">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.dropna()</span></code></pre></div>
</div>
<div class="cell markdown" id="r3r-rQRRItKx">
<p>To remove any missing rows</p>
</div>
<section id="data-preprocessing" class="cell markdown"
id="0EOs1pY_NYn_">
<h1>Data Preprocessing</h1>
</section>
<div class="cell code" data-execution_count="24" id="caukQu9VDzH7">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop(columns<span class="op">=</span>[<span class="st">&#39;Unnamed: 0&#39;</span>], errors<span class="op">=</span><span class="st">&#39;ignore&#39;</span>)</span></code></pre></div>
</div>
<div class="cell markdown" id="_HH5cvt7Tgsi">
<p>To remove the unnamed column</p>
</div>
<div class="cell code" data-execution_count="25"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="d3xBZMfT4UqN" data-outputId="f8ca49e4-e24d-4934-aae6-470e599a567f">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>df.columns</span></code></pre></div>
<div class="output execute_result" data-execution_count="25">
<pre><code>Index([&#39;rating&#39;, &#39;header&#39;, &#39;author&#39;, &#39;date&#39;, &#39;place&#39;, &#39;content&#39;, &#39;aircraft&#39;,
       &#39;traveller_type&#39;, &#39;seat_type&#39;, &#39;route&#39;, &#39;date_flown&#39;, &#39;seat_comfort&#39;,
       &#39;cabin_staff_service&#39;, &#39;food_beverages&#39;, &#39;ground_service&#39;,
       &#39;value_for_money&#39;, &#39;recommended&#39;, &#39;entertainment&#39;, &#39;trip_verified&#39;],
      dtype=&#39;object&#39;)</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="26"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:501}"
data-collapsed="true" id="f_oWleY9JjIH"
data-outputId="69346f13-0732-47c1-fc47-326c6e78bd02">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[[<span class="st">&quot;content&quot;</span>, <span class="st">&quot;recommended&quot;</span>]]</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>df.columns <span class="op">=</span> [<span class="st">&quot;text&quot;</span>, <span class="st">&quot;label&quot;</span>]</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>le <span class="op">=</span> sklearn.preprocessing.LabelEncoder()</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&quot;label&quot;</span>] <span class="op">=</span> le.fit_transform(df[<span class="st">&quot;label&quot;</span>])</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>number_of_classes <span class="op">=</span> df[<span class="st">&quot;label&quot;</span>].nunique()</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>df.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="26">

  <div id="df-0ea3312c-ebc0-4947-9147-233ac4d34579" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Just returned from Chicago, flew out 10 days ago on American Airlines absolutely superb in every way, had high expectations on return flight with BA. What a disappointment. The Airbus A380 may be nice from a pilots perspective but as a passenger it was awful. Very uncomfortable seats, the inflight entertainment and flight tracker failed to work throughout the flight, the inflight meal was inedible and the service was mediocre at best. Our short flight from Heathrow to Manchester was much improved, very welcoming and attentive in flight staff and the flight even arrived early. In future we will travel with one of the American carriers.</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>BA standards continue to decline every time I fly with them. This time, a 45 min late departure, which seems the norm for BA, and no information from the rude and clueless boarding gate staff. The Club lounge was overcrowded, dirty and grubby and cleaning staff could not cope. How many more cutbacks is BA going to apply before they become truly low cost. As a 35 year veteran user of BA, while people complained of Alex Cruz cutting costs, the past 3 years has seen them decline very quickly under their latest CEO. One reads the occasional article about BA improving things, but I have yet to see anything substantive. There seem to be few British staff left amongst the cabin crew, so maybe time for a name change and give the flag carrier status to a proper low-cost - and sadly the staff service has declined year on year. Onboard, the catering remains poor and surprised that Do&amp;Co can produce such rubbish meals when I have sampled their Turkish Airlines equivalent in August that was superb - guessing BA are too tight with their budget. Onboard WiFi service is a joke and should be avoided.</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Awful. Business class check in queue just as long as for economy, probably because half of the desks were not staffed and Terminal 5 is chaotic. Business lounge overfull, couldn't get seats. Delayed flight, unmanaged chaos at the gate. No drink on boarding, first drink served an hour after take-off. The meal was poor, used to get better in economy on other airlines. British Airways has won the race to the bottom of the cheapskate stakes. Not looking forward to the flight home.</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Not a reliable airline. You cannot trust the timing at all. I had a 6.45am flight, boarding was on time, but then we are sitting in the plane for already (1.5 hours) and the expected departure is still not clear. They have discovered the engine is not working! I am risking to be late for a business meeting in Geneva. How come they bring a not working plane to the gate. The funny thing is that I had another business trip in spring 2023, also with BA to Amsterdam. When I arrived to the Airport that time - I was told I don't have a seat. I was put on the next flight in several hours, which should have get me to the business meeting late, but still not too much. A lot of stress. In the end, on the second plane we were sitting in the cabin for 1.5 hours and I have missed the meeting. I thought it was a dramatic unlucky case that time, but today I see it's routine for BA not to fly on time.</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>The airplanes and the lounges are worn out, old and broken. From Dallas to Heathrow, multiple first class seating and electronics were non functional and poorly designed. The first class seating from Heathrow to Dubrovnik was nothing more than a tray blocking the middle seat of a standard coach ticket. Very disappointed.</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-0ea3312c-ebc0-4947-9147-233ac4d34579')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-0ea3312c-ebc0-4947-9147-233ac4d34579 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-0ea3312c-ebc0-4947-9147-233ac4d34579');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-bfe9c038-9f2f-4232-adaf-b56557a2b5ae">
  <button class="colab-df-quickchart" onclick="quickchart('df-bfe9c038-9f2f-4232-adaf-b56557a2b5ae')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-bfe9c038-9f2f-4232-adaf-b56557a2b5ae button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

    </div>
  </div>

</div>
</div>
<div class="cell markdown" id="44vSvz-hKJEo">
<p>I started by the relevant columns: Distributed into 2 parts
(preprocessed- label) which are (content- recommended), then I renamed
as(text- label) to make it easier working with the dataset. then I
created the LabelEncoder to convert all labels from categorical(text)
into numerical values. As for "no" will be 0 and for "yes" will be 1 (in
recommendations).</p>
</div>
<div class="cell code" data-execution_count="27"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:848}"
id="MDhSHyHnJeQ_" data-outputId="c82c8a42-1100-44c7-82b4-eb421c92b851">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> os <span class="im">import</span> remove</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">&#39;punkt_tab&#39;</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">&#39;stopwords&#39;</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">&#39;wordnet&#39;</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>lemmatizer <span class="op">=</span> WordNetLemmatizer()</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> remove_irrelevant_chars(text):</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">&#39;&#39;</span>.join(char <span class="cf">for</span> char <span class="kw">in</span> text <span class="cf">if</span> char.isalnum() <span class="kw">or</span> char.isspace())</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> to_lowercase(text):</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> text.lower()</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> remove_punctuation(text):</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">&#39;&#39;</span>.join(char <span class="cf">for</span> char <span class="kw">in</span> text <span class="cf">if</span> char <span class="kw">not</span> <span class="kw">in</span> string.punctuation)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> remove_stop_words(tokens):</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    stop_words <span class="op">=</span> <span class="bu">set</span>(stopwords.words(<span class="st">&#39;english&#39;</span>))</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [word <span class="cf">for</span> word <span class="kw">in</span> tokens <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> stop_words]</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lemmatize_words(tokens):</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [lemmatizer.lemmatize(word) <span class="cf">for</span> word <span class="kw">in</span> tokens]</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> clean_text(text):</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> remove_irrelevant_chars(text)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> to_lowercase(text)</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> remove_punctuation(text)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> word_tokenize(text)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> remove_stop_words(tokens)</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> lemmatize_words(tokens)</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> <span class="st">&quot; &quot;</span>.join(tokens)</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> text</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;cleaned_text&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;text&#39;</span>].<span class="bu">apply</span>(clean_text)</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>df[[<span class="st">&#39;text&#39;</span>, <span class="st">&#39;cleaned_text&#39;</span>]].head()</span></code></pre></div>
<div class="output stream stderr">
<pre><code>[nltk_data] Downloading package punkt_tab to /root/nltk_data...
[nltk_data]   Package punkt_tab is already up-to-date!
[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /root/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
</code></pre>
</div>
<div class="output execute_result" data-execution_count="27">

  <div id="df-280764fc-56f7-4b8b-99c3-1077aa0dbcb9" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>cleaned_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Just returned from Chicago, flew out 10 days ago on American Airlines absolutely superb in every way, had high expectations on return flight with BA. What a disappointment. The Airbus A380 may be nice from a pilots perspective but as a passenger it was awful. Very uncomfortable seats, the inflight entertainment and flight tracker failed to work throughout the flight, the inflight meal was inedible and the service was mediocre at best. Our short flight from Heathrow to Manchester was much improved, very welcoming and attentive in flight staff and the flight even arrived early. In future we will travel with one of the American carriers.</td>
      <td>returned chicago flew 10 day ago american airline absolutely superb every way high expectation return flight ba disappointment airbus a380 may nice pilot perspective passenger awful uncomfortable seat inflight entertainment flight tracker failed work throughout flight inflight meal inedible service mediocre best short flight heathrow manchester much improved welcoming attentive flight staff flight even arrived early future travel one american carrier</td>
    </tr>
    <tr>
      <th>1</th>
      <td>BA standards continue to decline every time I fly with them. This time, a 45 min late departure, which seems the norm for BA, and no information from the rude and clueless boarding gate staff. The Club lounge was overcrowded, dirty and grubby and cleaning staff could not cope. How many more cutbacks is BA going to apply before they become truly low cost. As a 35 year veteran user of BA, while people complained of Alex Cruz cutting costs, the past 3 years has seen them decline very quickly under their latest CEO. One reads the occasional article about BA improving things, but I have yet to see anything substantive. There seem to be few British staff left amongst the cabin crew, so maybe time for a name change and give the flag carrier status to a proper low-cost - and sadly the staff service has declined year on year. Onboard, the catering remains poor and surprised that Do&amp;Co can produce such rubbish meals when I have sampled their Turkish Airlines equivalent in August that was superb - guessing BA are too tight with their budget. Onboard WiFi service is a joke and should be avoided.</td>
      <td>ba standard continue decline every time fly time 45 min late departure seems norm ba information rude clueless boarding gate staff club lounge overcrowded dirty grubby cleaning staff could cope many cutback ba going apply become truly low cost 35 year veteran user ba people complained alex cruz cutting cost past 3 year seen decline quickly latest ceo one read occasional article ba improving thing yet see anything substantive seem british staff left amongst cabin crew maybe time name change give flag carrier status proper lowcost sadly staff service declined year year onboard catering remains poor surprised doco produce rubbish meal sampled turkish airline equivalent august superb guessing ba tight budget onboard wifi service joke avoided</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Awful. Business class check in queue just as long as for economy, probably because half of the desks were not staffed and Terminal 5 is chaotic. Business lounge overfull, couldn't get seats. Delayed flight, unmanaged chaos at the gate. No drink on boarding, first drink served an hour after take-off. The meal was poor, used to get better in economy on other airlines. British Airways has won the race to the bottom of the cheapskate stakes. Not looking forward to the flight home.</td>
      <td>awful business class check queue long economy probably half desk staffed terminal 5 chaotic business lounge overfull couldnt get seat delayed flight unmanaged chaos gate drink boarding first drink served hour takeoff meal poor used get better economy airline british airway race bottom cheapskate stake looking forward flight home</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Not a reliable airline. You cannot trust the timing at all. I had a 6.45am flight, boarding was on time, but then we are sitting in the plane for already (1.5 hours) and the expected departure is still not clear. They have discovered the engine is not working! I am risking to be late for a business meeting in Geneva. How come they bring a not working plane to the gate. The funny thing is that I had another business trip in spring 2023, also with BA to Amsterdam. When I arrived to the Airport that time - I was told I don't have a seat. I was put on the next flight in several hours, which should have get me to the business meeting late, but still not too much. A lot of stress. In the end, on the second plane we were sitting in the cabin for 1.5 hours and I have missed the meeting. I thought it was a dramatic unlucky case that time, but today I see it's routine for BA not to fly on time.</td>
      <td>reliable airline trust timing 645am flight boarding time sitting plane already 15 hour expected departure still clear discovered engine working risking late business meeting geneva come bring working plane gate funny thing another business trip spring 2023 also ba amsterdam arrived airport time told dont seat put next flight several hour get business meeting late still much lot stress end second plane sitting cabin 15 hour missed meeting thought dramatic unlucky case time today see routine ba fly time</td>
    </tr>
    <tr>
      <th>6</th>
      <td>The airplanes and the lounges are worn out, old and broken. From Dallas to Heathrow, multiple first class seating and electronics were non functional and poorly designed. The first class seating from Heathrow to Dubrovnik was nothing more than a tray blocking the middle seat of a standard coach ticket. Very disappointed.</td>
      <td>airplane lounge worn old broken dallas heathrow multiple first class seating electronics non functional poorly designed first class seating heathrow dubrovnik nothing tray blocking middle seat standard coach ticket disappointed</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-280764fc-56f7-4b8b-99c3-1077aa0dbcb9')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-280764fc-56f7-4b8b-99c3-1077aa0dbcb9 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-280764fc-56f7-4b8b-99c3-1077aa0dbcb9');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-75352c31-d47f-44f2-ae0a-4c5d6d3621f6">
  <button class="colab-df-quickchart" onclick="quickchart('df-75352c31-d47f-44f2-ae0a-4c5d6d3621f6')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-75352c31-d47f-44f2-ae0a-4c5d6d3621f6 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

    </div>
  </div>

</div>
</div>
<div class="cell markdown" id="S7Xn8chnNVNe">
<p>the aim of that code is to apply several cleaning steps, started by
removing the irrelevant characters liks symbols, etc, then lowercase to
convert all characters into lower ones, then removing any punctuations,
stop words like and, etc. then lemmatization for each word to convert
each word to its origin, then I define the clean_text function to
combine it into one cleaning pipeline.</p>
<p>Note: I added nltk.downlaod('stopwords') here not in the import
libraries at the beginning cause it didnt run when i added there so i
had to keep it inside the code itself.</p>
</div>
<section id="feauture-engineering" class="cell markdown"
id="onTZ8rE1O1TQ">
<h1>Feauture Engineering</h1>
</section>
<div class="cell code" data-execution_count="28"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="LSF7m5ElHKj9" data-outputId="dca489a7-d2e4-4626-9d3f-2db05d6533cb">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>tfidf_vectorizer <span class="op">=</span> TfidfVectorizer(max_features<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> tfidf_vectorizer.fit_transform(df[<span class="st">&#39;cleaned_text&#39;</span>])</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tfidf_vectorizer.get_feature_names_out())</span></code></pre></div>
<div class="output stream stdout">
<pre><code>[&#39;10&#39; &#39;12&#39; &#39;15&#39; &#39;20&#39; &#39;30&#39; &#39;40&#39; &#39;747&#39; &#39;777&#39; &#39;787&#39; &#39;a380&#39; &#39;able&#39;
 &#39;absolutely&#39; &#39;access&#39; &#39;across&#39; &#39;actually&#39; &#39;age&#39; &#39;agent&#39; &#39;ago&#39; &#39;ahead&#39;
 &#39;air&#39; &#39;aircraft&#39; &#39;airline&#39; &#39;airport&#39; &#39;airway&#39; &#39;aisle&#39; &#39;almost&#39; &#39;already&#39;
 &#39;also&#39; &#39;although&#39; &#39;always&#39; &#39;announcement&#39; &#39;another&#39; &#39;anything&#39; &#39;area&#39;
 &#39;around&#39; &#39;arrival&#39; &#39;arrived&#39; &#39;ask&#39; &#39;asked&#39; &#39;attendant&#39; &#39;attentive&#39;
 &#39;available&#39; &#39;average&#39; &#39;avios&#39; &#39;avoid&#39; &#39;away&#39; &#39;awful&#39; &#39;ba&#39; &#39;back&#39; &#39;bad&#39;
 &#39;bag&#39; &#39;baggage&#39; &#39;bar&#39; &#39;bed&#39; &#39;beef&#39; &#39;behind&#39; &#39;best&#39; &#39;better&#39; &#39;beverage&#39;
 &#39;big&#39; &#39;bit&#39; &#39;board&#39; &#39;boarded&#39; &#39;boarding&#39; &#39;boeing&#39; &#39;book&#39; &#39;booked&#39;
 &#39;booking&#39; &#39;bottle&#39; &#39;breakfast&#39; &#39;british&#39; &#39;broken&#39; &#39;budget&#39; &#39;bus&#39;
 &#39;business&#39; &#39;busy&#39; &#39;buy&#39; &#39;cabin&#39; &#39;call&#39; &#39;called&#39; &#39;came&#39; &#39;cancelled&#39; &#39;cant&#39;
 &#39;captain&#39; &#39;card&#39; &#39;care&#39; &#39;carrier&#39; &#39;case&#39; &#39;catering&#39; &#39;champagne&#39; &#39;change&#39;
 &#39;changed&#39; &#39;charge&#39; &#39;cheap&#39; &#39;check&#39; &#39;checked&#39; &#39;checkin&#39; &#39;cheese&#39; &#39;chicken&#39;
 &#39;child&#39; &#39;choice&#39; &#39;choose&#39; &#39;class&#39; &#39;clean&#39; &#39;clearly&#39; &#39;club&#39; &#39;coffee&#39;
 &#39;cold&#39; &#39;come&#39; &#39;comfort&#39; &#39;comfortable&#39; &#39;compared&#39; &#39;complaint&#39;
 &#39;configuration&#39; &#39;connecting&#39; &#39;connection&#39; &#39;control&#39; &#39;cost&#39; &#39;could&#39;
 &#39;couldnt&#39; &#39;couple&#39; &#39;course&#39; &#39;cramped&#39; &#39;crew&#39; &#39;customer&#39; &#39;cut&#39; &#39;cutting&#39;
 &#39;day&#39; &#39;decent&#39; &#39;decided&#39; &#39;deck&#39; &#39;delay&#39; &#39;delayed&#39; &#39;departed&#39; &#39;departure&#39;
 &#39;desk&#39; &#39;despite&#39; &#39;didnt&#39; &#39;difference&#39; &#39;different&#39; &#39;dinner&#39; &#39;dirty&#39;
 &#39;disappointed&#39; &#39;disappointing&#39; &#39;done&#39; &#39;dont&#39; &#39;drink&#39; &#39;due&#39; &#39;earlier&#39;
 &#39;early&#39; &#39;easy&#39; &#39;easyjet&#39; &#39;economy&#39; &#39;efficient&#39; &#39;either&#39; &#39;else&#39; &#39;empty&#39;
 &#39;end&#39; &#39;enough&#39; &#39;entertainment&#39; &#39;especially&#39; &#39;etc&#39; &#39;europe&#39; &#39;european&#39;
 &#39;even&#39; &#39;eventually&#39; &#39;ever&#39; &#39;every&#39; &#39;everyone&#39; &#39;everything&#39; &#39;excellent&#39;
 &#39;expect&#39; &#39;experience&#39; &#39;extra&#39; &#39;extremely&#39; &#39;fa&#39; &#39;fact&#39; &#39;fairly&#39; &#39;family&#39;
 &#39;far&#39; &#39;fare&#39; &#39;fast&#39; &#39;fault&#39; &#39;feel&#39; &#39;felt&#39; &#39;finally&#39; &#39;find&#39; &#39;fine&#39; &#39;first&#39;
 &#39;flew&#39; &#39;flight&#39; &#39;flown&#39; &#39;fly&#39; &#39;flying&#39; &#39;food&#39; &#39;forward&#39; &#39;found&#39; &#39;free&#39;
 &#39;friendly&#39; &#39;front&#39; &#39;full&#39; &#39;future&#39; &#39;galley&#39; &#39;gate&#39; &#39;gatwick&#39; &#39;gave&#39; &#39;get&#39;
 &#39;getting&#39; &#39;give&#39; &#39;given&#39; &#39;glass&#39; &#39;go&#39; &#39;going&#39; &#39;gold&#39; &#39;gone&#39; &#39;good&#39; &#39;got&#39;
 &#39;great&#39; &#39;ground&#39; &#39;group&#39; &#39;half&#39; &#39;hand&#39; &#39;happy&#39; &#39;hard&#39; &#39;haul&#39; &#39;heathrow&#39;
 &#39;help&#39; &#39;helpful&#39; &#39;high&#39; &#39;holiday&#39; &#39;home&#39; &#39;hot&#39; &#39;hour&#39; &#39;however&#39; &#39;ife&#39;
 &#39;im&#39; &#39;including&#39; &#39;inflight&#39; &#39;information&#39; &#39;informed&#39; &#39;instead&#39; &#39;issue&#39;
 &#39;ive&#39; &#39;joke&#39; &#39;journey&#39; &#39;kept&#39; &#39;know&#39; &#39;lack&#39; &#39;landed&#39; &#39;landing&#39; &#39;large&#39;
 &#39;last&#39; &#39;late&#39; &#39;later&#39; &#39;layout&#39; &#39;least&#39; &#39;left&#39; &#39;leg&#39; &#39;legroom&#39; &#39;less&#39;
 &#39;let&#39; &#39;level&#39; &#39;lhr&#39; &#39;light&#39; &#39;like&#39; &#39;limited&#39; &#39;line&#39; &#39;little&#39; &#39;london&#39;
 &#39;long&#39; &#39;longer&#39; &#39;look&#39; &#39;looked&#39; &#39;looking&#39; &#39;lost&#39; &#39;lot&#39; &#39;lounge&#39; &#39;low&#39;
 &#39;luggage&#39; &#39;lunch&#39; &#39;made&#39; &#39;main&#39; &#39;make&#39; &#39;managed&#39; &#39;many&#39; &#39;may&#39; &#39;meal&#39;
 &#39;mean&#39; &#39;meant&#39; &#39;member&#39; &#39;menu&#39; &#39;middle&#39; &#39;min&#39; &#39;minute&#39; &#39;missed&#39; &#39;money&#39;
 &#39;month&#39; &#39;morning&#39; &#39;movie&#39; &#39;much&#39; &#39;must&#39; &#39;narrow&#39; &#39;need&#39; &#39;never&#39; &#39;new&#39;
 &#39;next&#39; &#39;nice&#39; &#39;night&#39; &#39;nothing&#39; &#39;number&#39; &#39;offer&#39; &#39;offered&#39; &#39;offering&#39;
 &#39;ok&#39; &#39;okay&#39; &#39;old&#39; &#39;onboard&#39; &#39;one&#39; &#39;online&#39; &#39;open&#39; &#39;option&#39; &#39;order&#39;
 &#39;outbound&#39; &#39;overall&#39; &#39;paid&#39; &#39;part&#39; &#39;pas&#39; &#39;passenger&#39; &#39;past&#39; &#39;pay&#39;
 &#39;paying&#39; &#39;people&#39; &#39;person&#39; &#39;place&#39; &#39;plane&#39; &#39;pleasant&#39; &#39;plenty&#39; &#39;plus&#39;
 &#39;point&#39; &#39;polite&#39; &#39;poor&#39; &#39;possible&#39; &#39;premium&#39; &#39;pretty&#39; &#39;previous&#39; &#39;price&#39;
 &#39;prior&#39; &#39;priority&#39; &#39;probably&#39; &#39;problem&#39; &#39;process&#39; &#39;product&#39;
 &#39;professional&#39; &#39;provide&#39; &#39;provided&#39; &#39;put&#39; &#39;quality&#39; &#39;queue&#39; &#39;quick&#39;
 &#39;quickly&#39; &#39;quite&#39; &#39;rather&#39; &#39;real&#39; &#39;really&#39; &#39;reason&#39; &#39;reasonable&#39;
 &#39;received&#39; &#39;recommend&#39; &#39;rest&#39; &#39;return&#39; &#39;review&#39; &#39;right&#39; &#39;room&#39; &#39;route&#39;
 &#39;row&#39; &#39;rude&#39; &#39;run&#39; &#39;ryanair&#39; &#39;said&#39; &#39;salad&#39; &#39;sandwich&#39; &#39;sat&#39; &#39;say&#39;
 &#39;schedule&#39; &#39;screen&#39; &#39;seat&#39; &#39;seating&#39; &#39;second&#39; &#39;security&#39; &#39;see&#39; &#39;seem&#39;
 &#39;seemed&#39; &#39;seems&#39; &#39;selection&#39; &#39;serve&#39; &#39;served&#39; &#39;service&#39; &#39;serving&#39;
 &#39;several&#39; &#39;short&#39; &#39;side&#39; &#39;since&#39; &#39;singapore&#39; &#39;sit&#39; &#39;sitting&#39; &#39;sleep&#39;
 &#39;slightly&#39; &#39;slow&#39; &#39;small&#39; &#39;smooth&#39; &#39;snack&#39; &#39;someone&#39; &#39;something&#39; &#39;south&#39;
 &#39;space&#39; &#39;special&#39; &#39;staff&#39; &#39;standard&#39; &#39;start&#39; &#39;started&#39; &#39;still&#39; &#39;storage&#39;
 &#39;sure&#39; &#39;system&#39; &#39;t5&#39; &#39;take&#39; &#39;taken&#39; &#39;taking&#39; &#39;tasty&#39; &#39;tea&#39; &#39;terminal&#39;
 &#39;terrible&#39; &#39;thats&#39; &#39;thing&#39; &#39;think&#39; &#39;though&#39; &#39;thought&#39; &#39;three&#39;
 &#39;throughout&#39; &#39;ticket&#39; &#39;time&#39; &#39;tiny&#39; &#39;tired&#39; &#39;together&#39; &#39;toilet&#39; &#39;told&#39;
 &#39;took&#39; &#39;top&#39; &#39;track&#39; &#39;travel&#39; &#39;traveller&#39; &#39;travelling&#39; &#39;tray&#39; &#39;tried&#39;
 &#39;trip&#39; &#39;trolley&#39; &#39;try&#39; &#39;trying&#39; &#39;tv&#39; &#39;two&#39; &#39;uncomfortable&#39; &#39;understand&#39;
 &#39;unfortunately&#39; &#39;unless&#39; &#39;upgrade&#39; &#39;upper&#39; &#39;use&#39; &#39;used&#39; &#39;using&#39; &#39;usual&#39;
 &#39;value&#39; &#39;via&#39; &#39;wait&#39; &#39;waiting&#39; &#39;want&#39; &#39;wanted&#39; &#39;wasnt&#39; &#39;water&#39; &#39;way&#39;
 &#39;week&#39; &#39;well&#39; &#39;went&#39; &#39;whilst&#39; &#39;whole&#39; &#39;wife&#39; &#39;wifi&#39; &#39;window&#39; &#39;wine&#39;
 &#39;within&#39; &#39;without&#39; &#39;work&#39; &#39;worked&#39; &#39;working&#39; &#39;world&#39; &#39;worse&#39; &#39;worst&#39;
 &#39;worth&#39; &#39;would&#39; &#39;wrong&#39; &#39;year&#39;]
</code></pre>
</div>
</div>
<div class="cell markdown" id="WI9qCVHSRSTg">
<p>I used TF-IDF vectorizer to convert the text data into numerical one,
and to reduce the common words, then I applied it on the new column
(cleaned_text), then I printed the most important 500 words in the
text.</p>
</div>
<section id="bigram-model-training" class="cell markdown"
id="kMpus7xyYMH_">
<h1>Bigram Model Training</h1>
</section>
<div class="cell code" data-execution_count="29" id="5mJvNodvH7-H">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>sentences <span class="op">=</span> [text <span class="cf">for</span> text <span class="kw">in</span> df[<span class="st">&#39;cleaned_text&#39;</span>]]</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>random.shuffle(sentences)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>split_index <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.8</span> <span class="op">*</span> <span class="bu">len</span>(sentences))</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>train_sentences <span class="op">=</span> sentences[:split_index]</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>test_sentences <span class="op">=</span> sentences[split_index:]</span></code></pre></div>
</div>
<div class="cell markdown" id="uAsxlBLtlTWI">
<p>I extracted to cleaned text column that already has been
preprocessed, then shuffle the list of sentences randomly, then split
the data as 80% for training and 20% for testing</p>
</div>
<section id="train-the-bigram-model" class="cell markdown"
id="JaegqsanYPct">
<h1>Train the bigram model</h1>
</section>
<div class="cell code" data-execution_count="30" id="Rx0anVZ5IVpd">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>train_tokens <span class="op">=</span> [<span class="bu">list</span>(nltk.word_tokenize(sentence)) <span class="cf">for</span> sentence <span class="kw">in</span> train_sentences]</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>train_data_bigram, vocab_bigram <span class="op">=</span> nltk.lm.preprocessing.padded_everygram_pipeline(<span class="dv">2</span>, train_tokens)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>bigram_model <span class="op">=</span> nltk.lm.models.Laplace(<span class="dv">2</span>)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>bigram_model.fit(train_data_bigram, vocab_bigram)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>test_tokens <span class="op">=</span> [<span class="bu">list</span>(nltk.word_tokenize(sentence)) <span class="cf">for</span> sentence <span class="kw">in</span> test_sentences]</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>test_data_bigram, _ <span class="op">=</span> nltk.lm.preprocessing.padded_everygram_pipeline(<span class="dv">2</span>, test_tokens)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>test_data_bigram <span class="op">=</span> [<span class="bu">list</span>(everygrams) <span class="cf">for</span> everygrams <span class="kw">in</span> test_data_bigram]</span></code></pre></div>
</div>
<div class="cell markdown" id="Knb06dPpmcsm">
<p>I started by converting the training sentences into bigrams(to break
down the sentences) and padding the sentences(to let the word do not
have a following word) at both ends.</p>
</div>
<section id="perplexity-calculation" class="cell markdown"
id="kj8KLGDIYbdk">
<h1>Perplexity Calculation</h1>
</section>
<div class="cell code" data-execution_count="31"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="Pd0tnfV3I6kq" data-outputId="df4a81f2-a7cd-421a-f95a-734c5c17dd7e">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>preplexity_bigram <span class="op">=</span> bigram_model.perplexity(test_data_bigram)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Perplexity of Bigram Model on Test Data: </span><span class="sc">{</span><span class="bu">int</span>(preplexity_bigram)<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Perplexity of Bigram Model on Test Data: 8127
</code></pre>
</div>
</div>
<div class="cell markdown" id="IsyFkOurnf0I">
<p>Calculate the perplexity to measure how well the model will predict
the test data</p>
</div>
<div class="cell code" data-execution_count="32"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="XWh1Y1HsI-HM" data-outputId="4ad87882-0f2a-42ef-b36c-5fa98871a5cf">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>log_likelihood <span class="op">=</span> bigram_model.score(test_data_bigram)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Log-likelihood of Bigram Model: </span><span class="sc">{</span>log_likelihood<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Log-likelihood of Bigram Model: 9.286861876503311e-06
</code></pre>
</div>
</div>
<div class="cell markdown" id="KsmHZKLlp_vQ">
<p>Evaluate the probability of the test under the trained model</p>
</div>
<section id="dataset-splitting-train-test" class="cell markdown"
id="GoR44bmbWpXx">
<h1>Dataset Splitting Train-Test</h1>
</section>
<div class="cell code" data-execution_count="33"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="PL9Mzfc5HP9A" data-outputId="6123db44-2d38-4261-8703-c040b79ff70b">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>vectorizer <span class="op">=</span> TfidfVectorizer(max_features<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> df[<span class="st">&quot;text&quot;</span>]</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">&quot;label&quot;</span>]</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>x_train, x_test, y_train, y_test <span class="op">=</span> sklearn.model_selection.train_test_split(x, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>x_train <span class="op">=</span> vectorizer.fit_transform(x_train).toarray()</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>x_test <span class="op">=</span> vectorizer.transform(x_test).toarray()</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;new_x_train:&quot;</span>, x_train.shape)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;new_x_test:&quot;</span>, x_test.shape)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>new_x_train: (1058, 500)
new_x_test: (265, 500)
</code></pre>
</div>
</div>
<div class="cell markdown" id="7K0n87CTVx3d">
<p>I extracted text and label columns and assigned it to x and y, as x
will be the feature and y will be my target. then I splitted the data
into training(80%) and testing(20%). then I applied the TF-IDF
transformation into the text data. then I used toarray function to
convert the sparse matrix into dense array, so I avoided that as the
sparse matrix only storage non zeros values. then I printed x and y
after the splitting.</p>
</div>
<section id="model-training---random-forest" class="cell markdown"
id="5qmimJqaXs3Q">
<h1>Model Training - Random Forest</h1>
</section>
<div class="cell code" data-execution_count="34"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="gihPWVFRHqt8" data-outputId="724817cf-b714-44e9-efe0-477f4d0d304a">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>parameters_grid <span class="op">=</span> {</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;criterion&quot;</span>: [<span class="st">&quot;gini&quot;</span>, <span class="st">&quot;entropy&quot;</span>],</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;n_estimators&quot;</span>: <span class="bu">range</span>(<span class="dv">200</span>, <span class="dv">310</span>, <span class="dv">30</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sklearn.model_selection.GridSearchCV(sklearn.ensemble.RandomForestClassifier(),</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>                                             parameters_grid, scoring<span class="op">=</span><span class="st">&quot;accuracy&quot;</span>, cv<span class="op">=</span><span class="dv">5</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>model. fit(x_train, y_train)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;Accuracy of best Random Forest classfier = </span><span class="sc">{:.2f}</span><span class="st">&quot;</span>.<span class="bu">format</span>(model.best_score_))</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Best found hyperparameters of Random Forest classfier = )&quot;</span>.<span class="bu">format</span>(model.best_params_))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Accuracy of best Random Forest classfier = 0.86
Best found hyperparameters of Random Forest classfier = )
</code></pre>
</div>
</div>
<div class="cell markdown" id="rjNN2NJJX_3E">
<p>I used the traditional machine learning model "RandomForest" as its a
text dataset, I started by defining the hyperparameters, then
GridsearchCV to choose the best combination of the hyperparameters. then
the accuracy to check the maximize one, cv is 5 to split it into 5 parts
so the model can be trained 5 times. then (model.fit) to train the
random forest model on the training data. then I printed to check the
accuracy.</p>
</div>
<section id="model-evaluation" class="cell markdown" id="sYoKWMPBbowj">
<h1>Model Evaluation</h1>
</section>
<div class="cell code" data-execution_count="35"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="JG4f-_ThHzC5" data-outputId="aa1dd4fe-0081-46cc-b28e-3575a5b4fbb6">
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>y_predicted <span class="op">=</span> model.predict(x_test)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> sklearn.metrics.accuracy_score(y_test, y_predicted)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;Accuracy = </span><span class="sc">{:.2f}</span><span class="st">&quot;</span>.<span class="bu">format</span>(accuracy))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Accuracy = 0.81
</code></pre>
</div>
</div>
<div class="cell markdown" id="H-M8KPlqc_YY">
<p>I trained the model to make predictions on the test data, the compare
the predicted labels with the true labels.</p>
</div>
<div class="cell code" data-execution_count="36"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="8pHo6FVhH2oi" data-outputId="11ae2169-165a-4119-c45d-cb93af0f10eb">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_test, y_predicted)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>precision <span class="op">=</span> precision_score(y_test, y_predicted)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> recall_score(y_test, y_predicted)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> f1_score(y_test, y_predicted)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Precision: </span><span class="sc">{</span>precision<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Recall: </span><span class="sc">{</span>recall<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;F1 Score: </span><span class="sc">{</span>f1<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Accuracy: 0.81
Precision: 0.80
Recall: 0.71
F1 Score: 0.75
</code></pre>
</div>
</div>
<div class="cell markdown" id="1GEZ7MuXdhvn">
<p>Here to check the performance of the model, the precision to check
how many of the predicted (yes) are really yes, then the recall to check
how many actual yes are corectly identified, the last one F1 score is a
balanced one that consider both(precision and recall). And I did in that
way so it will be easy to create a comparison after i create another
model, so I will be able to check the comparison in 4 parts (accuracy-
precision- recall- f1)</p>
</div>
<section id="transformer-model-training-distilroberta"
class="cell markdown" id="zDr-M4P9Ykkd">
<h1>Transformer Model Training (DistilRoBERTa)</h1>
</section>
<div class="cell code" data-execution_count="37"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:432,&quot;referenced_widgets&quot;:[&quot;5d5e9b9852dd496cad82fc246c7ab8b9&quot;,&quot;b6c277844a78422faa12acbceef1a026&quot;,&quot;350a1481c0f84dfb8e71d5b38b328f2b&quot;,&quot;3327d01997e7454da55ed59f1d480212&quot;,&quot;e29274bb460042a5b73f5e2c2033f0a4&quot;,&quot;636f4641315849c6a9e85a6fc54183d4&quot;,&quot;561afac2b0f24369ad82bce44b2fcb4a&quot;,&quot;0734302669c3450ebf2f4ccd6850147f&quot;,&quot;5e75e71aba0e4df7aa475c03134fdf1b&quot;,&quot;62d0122873904dfd953ffaa6b466538b&quot;,&quot;1fd66ee4fec34b528aee99a6220d8929&quot;,&quot;ac028001509f44a0865acf786813a81e&quot;,&quot;2a78346511584354b38e0d7fbece1fba&quot;,&quot;bbf66dcd21f446638d8e43677136f774&quot;,&quot;7b395a0034124ffb82783165a77c2909&quot;,&quot;b293d69cf2a14d45b2368586bece9136&quot;,&quot;be9b020fc4e94b81a436a9a8c7e34845&quot;,&quot;5fa68d60ddba42b4a702a1827d8a88bc&quot;,&quot;cac407ae06e64133b812a79f8013cf9c&quot;,&quot;b060144a72404b65bfd62d9c027bffc1&quot;,&quot;9d0d3273764744c9b10b5f3fc9236aba&quot;,&quot;18137d7a929b4f2193685ae56c8cfa0e&quot;,&quot;f080917fe1e74884ad02e6a1ebda47b8&quot;,&quot;8c47ca58d8a94de38feaddb89da55721&quot;,&quot;8f86861861b944008584e966e847b4e5&quot;,&quot;6a4c0b66be994221a4206b31790f23e4&quot;,&quot;30675966ff63489595641fc955ef4aea&quot;,&quot;bebe58b64edc498e8bcd10d2691cf134&quot;,&quot;281c0faa01414bcc92908564cc73ccc9&quot;,&quot;aa52f7f3ee434c89aefc9fa546520603&quot;,&quot;7270674ebc874ad2877089b6f843bacc&quot;,&quot;1b3a02b71f9b491bb0368c27f7cfe625&quot;,&quot;266c396beef144f685c7e1e75ac7a757&quot;,&quot;1b1eee6d91d74edcad00fdf4b5ab2ce7&quot;,&quot;762f8426a2b84480bb03eee4f3f1c751&quot;,&quot;7e380bd21d3040faadfb6e5854604bda&quot;,&quot;e1d1ea6fbb2d453590f3450db5db0d1c&quot;,&quot;75946ce60dd24aae8a5e2df0745dec98&quot;,&quot;1af3d64ff5854d0997ac07373ad9b093&quot;,&quot;524c27ecb7ab43849e645b035fdc29ec&quot;,&quot;b1931a7817c140898989720a069d6583&quot;,&quot;bb638cc6970a4162ad7c90477d25ce79&quot;,&quot;632f31978ed442ac9777f3f140e90ad9&quot;,&quot;9299bbe70b8e420a8d5035e5eefb2268&quot;,&quot;3268cd010b99482d90a03e135d1b37bd&quot;,&quot;613f6b040d15403c84136ab5b2fb6d30&quot;,&quot;2c5025aab5684129b0449c6b9d9e267f&quot;,&quot;08732fd724c14dd9b300212398d5c66b&quot;,&quot;36cd0359b3704ea0b4f42d76129072e2&quot;,&quot;06450c874a174aaf8c177c3d879c1971&quot;,&quot;4b3a421ede704c81ba20d219068cacda&quot;,&quot;3d0bb1d41d074719a0c58d30db2fe9ba&quot;,&quot;5804b3b665c94b91b729e84668b542ce&quot;,&quot;d0d6e1de618540c582250add3a95836c&quot;,&quot;b753e36d3a9f40c5b6f9e6499331ddee&quot;,&quot;3913019eeba54c39a10c4e53f5f77ac7&quot;,&quot;1d6fafda680a4fe588a5f3a698066bc9&quot;,&quot;d6e562a6f1b74beeaa6f885b4276cfee&quot;,&quot;8c7ef311ea6f45cfa005d3b3771a92e6&quot;,&quot;27787933d8fc4f749ef712a3f8425ea9&quot;,&quot;1eb9807f45974d0ea3cf74863678998e&quot;,&quot;23c6da254a2243feb4881699bf809a59&quot;,&quot;9da43e5c01124c9a9f301e0a891d55e1&quot;,&quot;990f0fcd4a6645009b1bfd1e6c4c7159&quot;,&quot;cd8bdafacdde44e89e146c2e63cb04fd&quot;,&quot;8cc53eaa30ce40499b2b315e4f31a8de&quot;,&quot;5c58a35f63c049829cdbdd27d619c4a6&quot;,&quot;d2a9eeacbb1641e7ad6b042739a1db15&quot;,&quot;e0197e9befaa4f3db9e322a50daafa30&quot;,&quot;24ce740ca725408ebdad473c388a6f82&quot;,&quot;7a98d501494043b5b7b97d833942c217&quot;,&quot;909e33768cdd4584a12ba13f13f49539&quot;,&quot;c3e49a7255e14c8e986870173db58770&quot;,&quot;f4f65a64ed8c43c5b5ac4298d4e1d4dd&quot;,&quot;a24a4e72dc754276979f40ff72324c96&quot;,&quot;c169cedcf2b945f18c7858c9742952e4&quot;,&quot;ee6171bd67ad4977a844f3c82b1ac9b6&quot;,&quot;f856e96da33c4769b271714a6f018309&quot;,&quot;ee4cc818b18f4919ae65a1bc6fea35dd&quot;,&quot;be9df16948f946dbb9e8c626f25b4546&quot;,&quot;3050d025059a46068033f2286c062531&quot;,&quot;29089532ed854071a86614b1bf735e8c&quot;,&quot;af8f2df9c6874767b2e35b3f87f2b6f8&quot;,&quot;3392bce9d0994d0696fa9e39d7185b38&quot;,&quot;34d8142795d643a99fe51237d8590559&quot;,&quot;359d619e84764e35a5b77c752d25e044&quot;,&quot;d3ac0cf2398841f8b415b9b1df9c1998&quot;,&quot;6c0ca8733b7d41bbb446a407cae8f126&quot;]}"
data-collapsed="true" id="VlnfG5v_bPp0"
data-outputId="c311953e-4939-4383-f2b0-08dfba3e0b37">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">&quot;distilroberta-base&quot;</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> transformers.AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>df_train, df_test <span class="op">=</span> train_test_split(df, test_size<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>df_train[<span class="st">&#39;encoded_labels&#39;</span>] <span class="op">=</span> label_encoder.fit_transform(df_train[<span class="st">&#39;label&#39;</span>])</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>df_test[<span class="st">&#39;encoded_labels&#39;</span>] <span class="op">=</span> label_encoder.transform(df_test[<span class="st">&#39;label&#39;</span>])</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess_function(examples):</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer(examples[<span class="st">&quot;text&quot;</span>], truncation<span class="op">=</span><span class="va">True</span>, padding<span class="op">=</span><span class="st">&quot;max_length&quot;</span>, max_length<span class="op">=</span><span class="dv">512</span>)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> datasets.Dataset.from_pandas(df_train)</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> datasets.Dataset.from_pandas(df_test)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> train_dataset.<span class="bu">map</span>(preprocess_function, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> test_dataset.<span class="bu">map</span>(preprocess_function, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> train_dataset.rename_column(<span class="st">&quot;encoded_labels&quot;</span>, <span class="st">&quot;labels&quot;</span>)</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> test_dataset.rename_column(<span class="st">&quot;encoded_labels&quot;</span>, <span class="st">&quot;labels&quot;</span>)</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>data_collator <span class="op">=</span> transformers.DataCollatorWithPadding(tokenizer<span class="op">=</span>tokenizer)</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> transformers.AutoModelForSequenceClassification.from_pretrained(model_name, num_labels<span class="op">=</span><span class="bu">len</span>(df[<span class="st">&#39;label&#39;</span>].unique()))</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: 
The secret `HF_TOKEN` does not exist in your Colab secrets.
To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.
You will be able to reuse this secret in all of your notebooks.
Please note that authentication is recommended but still optional to access public models or datasets.
  warnings.warn(
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb37"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;5d5e9b9852dd496cad82fc246c7ab8b9&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb38"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;ac028001509f44a0865acf786813a81e&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb39"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;f080917fe1e74884ad02e6a1ebda47b8&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb40"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;1b1eee6d91d74edcad00fdf4b5ab2ce7&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb41"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;3268cd010b99482d90a03e135d1b37bd&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb42"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;3913019eeba54c39a10c4e53f5f77ac7&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb43"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;5c58a35f63c049829cdbdd27d619c4a6&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb44"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;f856e96da33c4769b271714a6f018309&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: [&#39;classifier.dense.bias&#39;, &#39;classifier.dense.weight&#39;, &#39;classifier.out_proj.bias&#39;, &#39;classifier.out_proj.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre>
</div>
</div>
<div class="cell markdown" id="8qB2bGffsDDS">
<p>The model name "distilroberta-base" to define the pre trained model
as its a smaller version of roberta, (the tokenizerr is intialized to
convert the text to tokens Ids) then I splitted the data into training
and testing. labels here are encoded as its converted to numerical
values.</p>
<p>then I applied the preprcess function to each example in the dataset,
(512 tokens as length cause this is the maximum in distilrobera so i
cant 513 for example). then i used the data collator to add padding to
the input sequences so all the sentences in a batch are the same
length.</p>
<p>note: I got inspired from a code on the internet and i added the
reference in reference part.</p>
</div>
<section id="define-training-arguments" class="cell markdown"
id="AxZ0fs-lZkC9">
<h1>Define training arguments</h1>
</section>
<div class="cell code" data-execution_count="38"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="nJ3KPrML3SQz" data-outputId="fcc89a8e-64fd-478f-a018-21020d18117a">
<div class="sourceCode" id="cb46"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> transformers.TrainingArguments(</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span><span class="st">&quot;./results&quot;</span>,</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    evaluation_strategy<span class="op">=</span><span class="st">&quot;steps&quot;</span>,</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>    per_device_eval_batch_size<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span><span class="fl">0.01</span>,</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>    logging_dir<span class="op">=</span><span class="st">&quot;./logs&quot;</span>,</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>    logging_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>    save_steps<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>    load_best_model_at_end<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>    fp16<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> transformers.Trainer(</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>    eval_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>    data_collator<span class="op">=</span>data_collator,</span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
&lt;ipython-input-38-526d962943b4&gt;:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = transformers.Trainer(
</code></pre>
</div>
</div>
<div class="cell markdown" id="uFKLRMtCsdD7">
<p>The training arguments define how the training here should be
conducted including the strategy, batch size, number of epochs, weight
decay, logging, etc. then the trainer intializes the trainer with the
model, training arguments, datasets, tokenizer(to encode the text and
the data collactor to handle the batching and padding .</p>
</div>
<section id="train-the-model" class="cell markdown" id="QShKQ-sgZnuj">
<h1>Train the model</h1>
</section>
<div class="cell code" data-execution_count="39"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:229}"
id="t7mnAg2P9aaN" data-outputId="7c69257f-81d6-44a1-9166-e655b25f9e78">
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> wandb</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>wandb.init(project<span class="op">=</span><span class="st">&quot;British Airline Review Dataset&quot;</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
</code></pre>
</div>
<div class="output display_data">
<pre><code>&lt;IPython.core.display.Javascript object&gt;</code></pre>
</div>
<div class="output stream stderr">
<pre><code>wandb: Logging into wandb.ai. (Learn how to deploy a W&amp;B server locally: https://wandb.me/wandb-server)
wandb: You can find your API key in your browser here: https://wandb.ai/authorize
wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:</code></pre>
</div>
<div class="output stream stdout">
<pre><code> ··········
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc
</code></pre>
</div>
<div class="output display_data">
Tracking run with wandb version 0.18.7
</div>
<div class="output display_data">
Run data is saved locally in <code>/content/wandb/run-20241213_131710-ugwpepq9</code>
</div>
<div class="output display_data">
Syncing run <strong><a href='https://wandb.ai/nouramrr2022-gisma-business-school/British%20Airline%20Review%20Dataset/runs/ugwpepq9' target="_blank">skilled-elevator-2</a></strong> to <a href='https://wandb.ai/nouramrr2022-gisma-business-school/British%20Airline%20Review%20Dataset' target="_blank">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target="_blank">docs</a>)<br/>
</div>
<div class="output display_data">
 View project at <a href='https://wandb.ai/nouramrr2022-gisma-business-school/British%20Airline%20Review%20Dataset' target="_blank">https://wandb.ai/nouramrr2022-gisma-business-school/British%20Airline%20Review%20Dataset</a>
</div>
<div class="output display_data">
 View run at <a href='https://wandb.ai/nouramrr2022-gisma-business-school/British%20Airline%20Review%20Dataset/runs/ugwpepq9' target="_blank">https://wandb.ai/nouramrr2022-gisma-business-school/British%20Airline%20Review%20Dataset/runs/ugwpepq9</a>
</div>
<div class="output execute_result" data-execution_count="39">
<button onClick="this.nextSibling.style.display='block';this.style.display='none';">Display W&B run</button><iframe src='https://wandb.ai/nouramrr2022-gisma-business-school/British%20Airline%20Review%20Dataset/runs/ugwpepq9?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>
</div>
</div>
<div class="cell markdown" id="YCeOvzYW-w23">
<p>I imported wandb cause when i train the model it wasn't working and
need an API key, so icreated an account.</p>
</div>
<div class="cell code" data-execution_count="40"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:175}"
data-collapsed="true" id="JFh6narhZiyL"
data-outputId="56b0b9d3-f3de-43da-8728-d3ebee7a276d">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>trainer.train()</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>trainer.save_model(<span class="st">&quot;./results&quot;</span> <span class="op">+</span> model_name)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
</code></pre>
</div>
<div class="output display_data">

    <div>
      
      <progress value='265' max='265' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [265/265 00:11, Epoch 1/1]
    </div>
    <table border="1" class="dataframe">
  <thead>
 <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>100</td>
      <td>0.612700</td>
      <td>0.647366</td>
    </tr>
    <tr>
      <td>200</td>
      <td>0.469100</td>
      <td>0.553624</td>
    </tr>
  </tbody>
</table><p>
</div>
</div>
<div class="cell markdown" id="M8mkHJuF2GSl">
<p>Started with the actual training process then the training model name
with the results.</p>
</div>
<section id="evaluate-the-model" class="cell markdown"
id="7sNqRDQ0o-iy">
<h1>Evaluate the model</h1>
</section>
<div class="cell code" data-execution_count="41"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
data-collapsed="true" id="MEAqjw77aVfU"
data-outputId="ae557053-beab-432f-95de-eff826c140c3">
<div class="sourceCode" id="cb56"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>eval_results <span class="op">=</span> trainer.evaluate()</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(eval_results)</span></code></pre></div>
<div class="output display_data">

    <div>
      
      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [67/67 00:00]
    </div>
    
</div>
<div class="output stream stdout">
<pre><code>{&#39;eval_loss&#39;: 0.45323479175567627, &#39;eval_runtime&#39;: 0.8223, &#39;eval_samples_per_second&#39;: 322.26, &#39;eval_steps_per_second&#39;: 81.477, &#39;epoch&#39;: 1.0}
</code></pre>
</div>
</div>
<div class="cell markdown" id="uDjYLuqg2Uxg">
<p>To evaluate the loop where the model is evaluated on the tested
dataset.</p>
</div>
<section id="predictions" class="cell markdown" id="CtKJ2OBbpL7N">
<h1>Predictions</h1>
</section>
<div class="cell code" data-execution_count="42"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
id="C-eUFydJeFmT" data-outputId="52558ac3-75d0-4438-8655-0ce2f4fab913">
<div class="sourceCode" id="cb58"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>predictions, labels, _ <span class="op">=</span> trainer.predict(test_dataset)</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>predicted_labels <span class="op">=</span> predictions.argmax(axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(labels, predicted_labels)</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>precision <span class="op">=</span> precision_score(labels, predicted_labels)</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> recall_score(labels, predicted_labels)</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> f1_score(labels, predicted_labels)</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Precision: </span><span class="sc">{</span>precision<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Recall: </span><span class="sc">{</span>recall<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;F1 Score: </span><span class="sc">{</span>f1<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output display_data">

</div>
<div class="output stream stdout">
<pre><code>Accuracy: 0.89
Precision: 0.89
Recall: 0.86
F1 Score: 0.88
</code></pre>
</div>
</div>
<div class="cell markdown" id="sek30MKy2uqh">
<p>I used the trainer object to get predictions for testing, which
returns 2 values: the prediction and the labels. then axis =-1 to
convert the predicted probabilities into labels. then check the metrics(
accuracy- precision- recall, f1 score) as I did in random forest
model.</p>
</div>
<section id="comparison-and-visualization" class="cell markdown"
id="TITCqr50pdh7">
<h1>Comparison and Visualization</h1>
</section>
<div class="cell code" data-execution_count="43"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="kmI_jecLkVuc" data-outputId="081b464c-0276-4cea-e7c4-3d31a3465f66">
<div class="sourceCode" id="cb60"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>rf_accuracy <span class="op">=</span> accuracy_score(y_test, y_predicted)</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>rf_precision <span class="op">=</span> precision_score(y_test, y_predicted)</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>rf_recall <span class="op">=</span> recall_score(y_test, y_predicted)</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>rf_f1 <span class="op">=</span> f1_score(y_test, y_predicted)</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>distilroberta_accuracy <span class="op">=</span> accuracy_score(labels, predicted_labels)</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>distilroberta_precision <span class="op">=</span> precision_score(labels, predicted_labels)</span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>distilroberta_recall <span class="op">=</span> recall_score(labels, predicted_labels)</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>distilroberta_f1 <span class="op">=</span> f1_score(labels, predicted_labels)</span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a>comparison_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Model&quot;</span>: [<span class="st">&quot;Model 1 (Traditional)&quot;</span>, <span class="st">&quot;Model 2 (DistilRoBERTa)&quot;</span>],</span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Accuracy&quot;</span>: [rf_accuracy, distilroberta_accuracy],</span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Precision&quot;</span>: [rf_precision, distilroberta_precision],</span>
<span id="cb60-15"><a href="#cb60-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Recall&quot;</span>: [rf_recall, distilroberta_recall],</span>
<span id="cb60-16"><a href="#cb60-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;F1 Score&quot;</span>: [rf_f1, distilroberta_f1]</span>
<span id="cb60-17"><a href="#cb60-17" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb60-18"><a href="#cb60-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-19"><a href="#cb60-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(comparison_df)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>                     Model  Accuracy  Precision    Recall  F1 Score
0    Model 1 (Traditional)  0.811321   0.800000  0.710280  0.752475
1  Model 2 (DistilRoBERTa)  0.894340   0.894737  0.864407  0.879310
</code></pre>
</div>
</div>
<div class="cell markdown" id="rV7RGVVi4Cmh">
<p>Here's the comparison between the best 2 models the traditional
one(random forest) and the deep learning one (distilrobera) to check
which one has the best accuracy, precision, recall and F1 score.</p>
</div>
<div class="cell code" data-execution_count="44"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
data-collapsed="true" id="I4OL5Nk15GAr"
data-outputId="50b7678a-b834-4825-9357-3a4eae7e2f81">
<div class="sourceCode" id="cb62"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> [<span class="st">&quot;Accuracy&quot;</span>, <span class="st">&quot;Precision&quot;</span>, <span class="st">&quot;Recall&quot;</span>, <span class="st">&quot;F1 Score&quot;</span>]</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>rf_scores <span class="op">=</span> [rf_accuracy, rf_precision, rf_recall, rf_f1]</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>distilroberta_scores <span class="op">=</span> [distilroberta_accuracy, distilroberta_precision, distilroberta_recall, distilroberta_f1]</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="bu">len</span>(metrics))</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>width <span class="op">=</span> <span class="fl">0.35</span></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>rects1 <span class="op">=</span> ax.bar(x <span class="op">-</span> width<span class="op">/</span><span class="dv">2</span>, rf_scores, width, label<span class="op">=</span><span class="st">&#39;Model 1 (Traditional)&#39;</span>)</span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>rects2 <span class="op">=</span> ax.bar(x <span class="op">+</span> width<span class="op">/</span><span class="dv">2</span>, distilroberta_scores, width, label<span class="op">=</span><span class="st">&#39;Model 2 (DistilRoBERTa)&#39;</span>)</span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">&#39;Metrics&#39;</span>)</span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">&#39;Scores&#39;</span>)</span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">&#39;Model Comparison&#39;</span>)</span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a>ax.set_xticks(x)</span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a>ax.set_xticklabels(metrics)</span>
<span id="cb62-17"><a href="#cb62-17" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb62-18"><a href="#cb62-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-19"><a href="#cb62-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> add_labels(rects):</span>
<span id="cb62-20"><a href="#cb62-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> rect <span class="kw">in</span> rects:</span>
<span id="cb62-21"><a href="#cb62-21" aria-hidden="true" tabindex="-1"></a>        height <span class="op">=</span> rect.get_height()</span>
<span id="cb62-22"><a href="#cb62-22" aria-hidden="true" tabindex="-1"></a>        ax.annotate(<span class="ss">f&#39;</span><span class="sc">{</span>height<span class="sc">:.2f}</span><span class="ss">&#39;</span>,</span>
<span id="cb62-23"><a href="#cb62-23" aria-hidden="true" tabindex="-1"></a>                    xy<span class="op">=</span>(rect.get_x() <span class="op">+</span> rect.get_width() <span class="op">/</span> <span class="dv">2</span>, height),</span>
<span id="cb62-24"><a href="#cb62-24" aria-hidden="true" tabindex="-1"></a>                    xytext<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">3</span>),</span>
<span id="cb62-25"><a href="#cb62-25" aria-hidden="true" tabindex="-1"></a>                    textcoords<span class="op">=</span><span class="st">&quot;offset points&quot;</span>,</span>
<span id="cb62-26"><a href="#cb62-26" aria-hidden="true" tabindex="-1"></a>                    ha<span class="op">=</span><span class="st">&#39;center&#39;</span>, va<span class="op">=</span><span class="st">&#39;bottom&#39;</span>)</span>
<span id="cb62-27"><a href="#cb62-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-28"><a href="#cb62-28" aria-hidden="true" tabindex="-1"></a>add_labels(rects1)</span>
<span id="cb62-29"><a href="#cb62-29" aria-hidden="true" tabindex="-1"></a>add_labels(rects2)</span>
<span id="cb62-30"><a href="#cb62-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-31"><a href="#cb62-31" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb62-32"><a href="#cb62-32" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_c1359fdbd9674af197c0dc0c23df42f3/cad97f78cff8a79a3132acefa11756156ea2360b.png" /></p>
</div>
</div>
<div class="cell markdown" id="Kc2ivOmM_LV6">
<p>I wanted to visualize the results to make it seen and easier to see
the difference between the 2 models. I started by defining the metrics
that will be comparised in my 2 models which are (accuracy- precision-
Recall- F1 score) then specify the width for each bar in the bar chart.
then i added the needed size for width and height for the bar chart
itself. then added my labels(metrics) and the title for the bar chart.
then i defined the labels for the chart (the numerical ones for each
bar) then i displayed the plot.</p>
</div>
<section id="conclusion" class="cell markdown" id="r9MpEQqwulrY">
<h1>Conclusion</h1>
</section>
<div class="cell markdown" id="sCoNQceau6hK">
<p>So at the end, here are some key points that I got it after the
anyalsis. The deep learning model (distilroberta model) acheived the
highest accuracy among the 3 models. The traditional model (Random
forest) also achieved a high accuracy which is 82% but the other model
have the highest rate, so I would recommend it.</p>
</div>
<section id="references" class="cell markdown" id="30sDR5Xf0h-b">
<h1>References</h1>
</section>
<div class="cell markdown" id="wVmvM9hN0kco">
<p><a href="https://yzsam.com/html/binuWt.html"
class="uri">https://yzsam.com/html/binuWt.html</a></p>
<p><a
href="https://discuss.huggingface.co/t/solution-for-graph-to-multiple-sentences-paragraph-generation/33826/2"
class="uri">https://discuss.huggingface.co/t/solution-for-graph-to-multiple-sentences-paragraph-generation/33826/2</a></p>
</div>
</body>
</html>
